"use strict";(self.webpackChunksynapseml=self.webpackChunksynapseml||[]).push([[5049],{3905:function(e,n,t){t.d(n,{Zo:function(){return u},kt:function(){return m}});var a=t(7294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,a,o=function(e,n){if(null==e)return{};var t,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var s=a.createContext({}),p=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},u=function(e){var n=p(e.components);return a.createElement(s.Provider,{value:n},e.children)},c={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},d=a.forwardRef((function(e,n){var t=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),d=p(t),m=o,h=d["".concat(s,".").concat(m)]||d[m]||c[m]||r;return t?a.createElement(h,l(l({ref:n},u),{},{components:t})):a.createElement(h,l({ref:n},u))}));function m(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var r=t.length,l=new Array(r);l[0]=d;var i={};for(var s in n)hasOwnProperty.call(n,s)&&(i[s]=n[s]);i.originalType=e,i.mdxType="string"==typeof e?e:o,l[1]=i;for(var p=2;p<r;p++)l[p]=t[p];return a.createElement.apply(null,l)}return a.createElement.apply(null,t)}d.displayName="MDXCreateElement"},5162:function(e,n,t){t.d(n,{Z:function(){return l}});var a=t(7294),o=t(6010),r="tabItem_Ymn6";function l(e){var n=e.children,t=e.hidden,l=e.className;return a.createElement("div",{role:"tabpanel",className:(0,o.Z)(r,l),hidden:t},n)}},5488:function(e,n,t){t.d(n,{Z:function(){return m}});var a=t(3117),o=t(7294),r=t(6010),l=t(2389),i=t(7392),s=t(7094),p=t(2466),u="tabList__CuJ",c="tabItem_LNqP";function d(e){var n,t,l=e.lazy,d=e.block,m=e.defaultValue,h=e.values,k=e.groupId,f=e.className,y=o.Children.map(e.children,(function(e){if((0,o.isValidElement)(e)&&"value"in e.props)return e;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})),v=null!=h?h:y.map((function(e){var n=e.props;return{value:n.value,label:n.label,attributes:n.attributes}})),b=(0,i.l)(v,(function(e,n){return e.value===n.value}));if(b.length>0)throw new Error('Docusaurus error: Duplicate values "'+b.map((function(e){return e.value})).join(", ")+'" found in <Tabs>. Every value needs to be unique.');var w=null===m?m:null!=(n=null!=m?m:null==(t=y.find((function(e){return e.props.default})))?void 0:t.props.value)?n:y[0].props.value;if(null!==w&&!v.some((function(e){return e.value===w})))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+w+'" but none of its children has the corresponding value. Available values are: '+v.map((function(e){return e.value})).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");var g=(0,s.U)(),S=g.tabGroupChoices,T=g.setTabGroupChoices,N=(0,o.useState)(w),E=N[0],x=N[1],O=[],D=(0,p.o5)().blockElementScrollPositionUntilNextRender;if(null!=k){var I=S[k];null!=I&&I!==E&&v.some((function(e){return e.value===I}))&&x(I)}var R=function(e){var n=e.currentTarget,t=O.indexOf(n),a=v[t].value;a!==E&&(D(n),x(a),null!=k&&T(k,String(a)))},M=function(e){var n,t=null;switch(e.key){case"Enter":R(e);break;case"ArrowRight":var a,o=O.indexOf(e.currentTarget)+1;t=null!=(a=O[o])?a:O[0];break;case"ArrowLeft":var r,l=O.indexOf(e.currentTarget)-1;t=null!=(r=O[l])?r:O[O.length-1]}null==(n=t)||n.focus()};return o.createElement("div",{className:(0,r.Z)("tabs-container",u)},o.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.Z)("tabs",{"tabs--block":d},f)},v.map((function(e){var n=e.value,t=e.label,l=e.attributes;return o.createElement("li",(0,a.Z)({role:"tab",tabIndex:E===n?0:-1,"aria-selected":E===n,key:n,ref:function(e){return O.push(e)},onKeyDown:M,onClick:R},l,{className:(0,r.Z)("tabs__item",c,null==l?void 0:l.className,{"tabs__item--active":E===n})}),null!=t?t:n)}))),l?(0,o.cloneElement)(y.filter((function(e){return e.props.value===E}))[0],{className:"margin-top--md"}):o.createElement("div",{className:"margin-top--md"},y.map((function(e,n){return(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==E})}))))}function m(e){var n=(0,l.Z)();return o.createElement(d,(0,a.Z)({key:String(n)},e))}},5102:function(e,n,t){t.r(n),t.d(n,{assets:function(){return d},contentTitle:function(){return u},default:function(){return k},frontMatter:function(){return p},metadata:function(){return c},toc:function(){return m}});var a=t(3117),o=t(102),r=(t(7294),t(3905)),l=t(5488),i=t(5162),s=["components"],p={title:".NET setup",hide_title:!0,sidebar_label:".NET setup",description:".NET setup"},u=".NET setup and example for SynapseML",c={unversionedId:"Reference/Dotnet Setup",id:"Reference/Dotnet Setup",title:".NET setup",description:".NET setup",source:"@site/docs/Reference/Dotnet Setup.md",sourceDirName:"Reference",slug:"/Reference/Dotnet Setup",permalink:"/SynapseML/docs/Reference/Dotnet Setup",draft:!1,tags:[],version:"current",frontMatter:{title:".NET setup",hide_title:!0,sidebar_label:".NET setup",description:".NET setup"},sidebar:"docs",previous:{title:"R setup",permalink:"/SynapseML/docs/Reference/R Setup"},next:{title:"Quickstart - LightGBM in Dotnet",permalink:"/SynapseML/docs/Reference/Quickstart - LightGBM in Dotnet"}},d={},m=[{value:"Installation",id:"installation",level:2},{value:"1. Install .NET",id:"1-install-net",level:3},{value:"2. Install Java",id:"2-install-java",level:3},{value:"3. Install Apache Spark",id:"3-install-apache-spark",level:3},{value:"4. Install .NET for Apache Spark",id:"4-install-net-for-apache-spark",level:3},{value:"5. Install WinUtils (Windows Only)",id:"5-install-winutils-windows-only",level:3},{value:"6. Set DOTNET_WORKER_DIR and check dependencies",id:"6-set-dotnet_worker_dir-and-check-dependencies",level:3},{value:"Write a .NET for SynapseML App",id:"write-a-net-for-synapseml-app",level:2},{value:"1. Create a console app",id:"1-create-a-console-app",level:3},{value:"2. Install NuGet package",id:"2-install-nuget-package",level:3},{value:"3. Write your app",id:"3-write-your-app",level:3},{value:"4. Run your .NET App",id:"4-run-your-net-app",level:3},{value:"Next",id:"next",level:2}],h={toc:m};function k(e){var n=e.components,t=(0,o.Z)(e,s);return(0,r.kt)("wrapper",(0,a.Z)({},h,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"net-setup-and-example-for-synapseml"},".NET setup and example for SynapseML"),(0,r.kt)("h2",{id:"installation"},"Installation"),(0,r.kt)("h3",{id:"1-install-net"},"1. Install .NET"),(0,r.kt)("p",null,"To start building .NET apps, you need to download and install the .NET SDK (Software Development Kit)."),(0,r.kt)("p",null,"Download and install the ",(0,r.kt)("a",{parentName:"p",href:"https://dotnet.microsoft.com/en-us/download/dotnet/3.1"},".NET Core SDK"),".\nInstalling the SDK adds the dotnet toolchain to your PATH."),(0,r.kt)("p",null,"Once you've installed the .NET Core SDK, open a new command prompt or terminal. Then run ",(0,r.kt)("inlineCode",{parentName:"p"},"dotnet"),"."),(0,r.kt)("p",null,"If the command runs and prints information about how to use dotnet, you can move to the next step.\nIf you receive a ",(0,r.kt)("inlineCode",{parentName:"p"},"'dotnet' is not recognized as an internal or external command")," error, make sure\nyou opened a new command prompt or terminal before running the command."),(0,r.kt)("h3",{id:"2-install-java"},"2. Install Java"),(0,r.kt)("p",null,"Install ",(0,r.kt)("a",{parentName:"p",href:"https://www.oracle.com/java/technologies/downloads/#java8"},"Java 8.1")," for Windows and macOS,\nor ",(0,r.kt)("a",{parentName:"p",href:"https://openjdk.org/install/"},"OpenJDK 8")," for Ubuntu."),(0,r.kt)("p",null,"Select the appropriate version for your operating system. For example, select jdk-8u201-windows-x64.exe\nfor a Windows x64 machine or jdk-8u231-macosx-x64.dmg for macOS. Then, use the command java to verify the installation."),(0,r.kt)("h3",{id:"3-install-apache-spark"},"3. Install Apache Spark"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://spark.apache.org/downloads.html"},"Download and install Apache Spark")," with version >= 3.2.0.\n(SynapseML v0.11.2 only supports spark version >= 3.2.0)"),(0,r.kt)("p",null,"Extract downloaded zipped files (with 7-Zip app on Windows or ",(0,r.kt)("inlineCode",{parentName:"p"},"tar")," on linux) and remember the location of\nextracted files, we take ",(0,r.kt)("inlineCode",{parentName:"p"},"~/bin/spark-3.2.0-bin-hadoop3.2/")," as an example here."),(0,r.kt)("p",null,"Run the following commands to set the environment variables used to locate Apache Spark.\nOn Windows, make sure to run the command prompt in administrator mode."),(0,r.kt)(l.Z,{groupId:"operating-systems",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"win",label:"Windows",default:!0,mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'  setx /M HADOOP_HOME C:\\bin\\spark-3.2.0-bin-hadoop3.2\\\n  setx /M SPARK_HOME C:\\bin\\spark-3.2.0-bin-hadoop3.2\\\n  setx /M PATH "%PATH%;%HADOOP_HOME%;%SPARK_HOME%bin" # Warning: Don\'t run this if your path is already long as it will truncate your path to 1024 characters and potentially remove entries!\n'))),(0,r.kt)(i.Z,{value:"linux",label:"Mac/Linux",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'  export SPARK_HOME=~/bin/spark-3.2.0-bin-hadoop3.2/\n  export PATH="$SPARK_HOME/bin:$PATH"\n  source ~/.bashrc\n')))),(0,r.kt)("p",null,"Once you've installed everything and set your environment variables, open a ",(0,r.kt)("strong",{parentName:"p"},"new")," command prompt or terminal and run the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"spark-submit --version\n")),(0,r.kt)("p",null,"If the command runs and prints version information, you can move to the next step."),(0,r.kt)("p",null,"If you receive a ",(0,r.kt)("inlineCode",{parentName:"p"},"'spark-submit' is not recognized as an internal or external command")," error, make sure you opened a ",(0,r.kt)("strong",{parentName:"p"},"new")," command prompt."),(0,r.kt)("h3",{id:"4-install-net-for-apache-spark"},"4. Install .NET for Apache Spark"),(0,r.kt)("p",null,"Download the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/dotnet/spark/releases"},"Microsoft.Spark.Worker")," ",(0,r.kt)("strong",{parentName:"p"},"v2.1.1")," release from the .NET for Apache Spark GitHub.\nFor example if you're on a Windows machine and plan to use .NET Core, download the Windows x64 netcoreapp3.1 release."),(0,r.kt)("p",null,"Extract Microsoft.Spark.Worker and remember the location."),(0,r.kt)("h3",{id:"5-install-winutils-windows-only"},"5. Install WinUtils (Windows Only)"),(0,r.kt)("p",null,".NET for Apache Spark requires WinUtils to be installed alongside Apache Spark.\n",(0,r.kt)("a",{parentName:"p",href:"https://github.com/steveloughran/winutils/blob/master/hadoop-3.0.0/bin/winutils.exe"},"Download winutils.exe"),".\nThen, copy WinUtils into C:\\bin\\spark-3.2.0-bin-hadoop3.2\\bin."),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"If you're using a different version of Hadoop, select the version of WinUtils that's compatible with your version of Hadoop. You can see the Hadoop version at the end of your Spark install folder name.")),(0,r.kt)("h3",{id:"6-set-dotnet_worker_dir-and-check-dependencies"},"6. Set DOTNET_WORKER_DIR and check dependencies"),(0,r.kt)("p",null,"Run one of the following commands to set the DOTNET_WORKER_DIR environment variable, which is used by .NET apps to locate .NET for Apache Spark\nworker binaries. Make sure to replace <PATH-DOTNET_WORKER_DIR> with the directory where you downloaded and extracted the Microsoft.Spark.Worker.\nOn Windows, make sure to run the command prompt in administrator mode."),(0,r.kt)(l.Z,{groupId:"operating-systems",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"win",label:"Windows",default:!0,mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"  setx /M DOTNET_WORKER_DIR <PATH-DOTNET-WORKER-DIR>\n"))),(0,r.kt)(i.Z,{value:"linux",label:"Mac/Linux",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"  export DOTNET_WORKER_DIR=<PATH-DOTNET-WORKER-DIR>\n")))),(0,r.kt)("p",null,"Finally, double-check that you can run ",(0,r.kt)("inlineCode",{parentName:"p"},"dotnet, java, spark-shell")," from your command line before you move to the next section."),(0,r.kt)("h2",{id:"write-a-net-for-synapseml-app"},"Write a .NET for SynapseML App"),(0,r.kt)("h3",{id:"1-create-a-console-app"},"1. Create a console app"),(0,r.kt)("p",null,"In your command prompt or terminal, run the following commands to create a new console application:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-powershell"},"dotnet new console -o SynapseMLApp\ncd SynapseMLApp\n")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"dotnet")," command creates a new application of type console for you. The -o parameter creates a directory\nnamed ",(0,r.kt)("inlineCode",{parentName:"p"},"SynapseMLApp")," where your app is stored and populates it with the required files.\nThe ",(0,r.kt)("inlineCode",{parentName:"p"},"cd SynapseMLApp")," command changes the directory to the app directory you created."),(0,r.kt)("h3",{id:"2-install-nuget-package"},"2. Install NuGet package"),(0,r.kt)("p",null,"To use .NET for Apache Spark in an app, install the Microsoft.Spark package.\nIn your command prompt or terminal, run the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-powershell"},"dotnet add package Microsoft.Spark --version 2.1.1\n")),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"This tutorial uses Microsoft.Spark version 2.1.1 as SynapseML 0.11.2 depends on it.\nChange to corresponding version if necessary.")),(0,r.kt)("p",null,"To use SynapseML features in the app, install SynapseML.X package.\nIn this tutorial, we use SynapseML.Cognitive as an example.\nIn your command prompt or terminal, run the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-powershell"},"# Update Nuget Config to include SynapseML Feed\ndotnet nuget add source https://mmlspark.blob.core.windows.net/synapsemlnuget/index.json -n SynapseMLFeed\ndotnet add package SynapseML.Cognitive --version 0.11.2\n")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"dotnet nuget add")," command adds SynapseML's resolver to the source, so that our package can be found."),(0,r.kt)("h3",{id:"3-write-your-app"},"3. Write your app"),(0,r.kt)("p",null,"Open Program.cs in Visual Studio Code, or any text editor. Replace its contents with this code:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-csharp"},'using System;\nusing System.Collections.Generic;\nusing Synapse.ML.Cognitive;\nusing Microsoft.Spark.Sql;\nusing Microsoft.Spark.Sql.Types;\n\nnamespace SynapseMLApp\n{\n    class Program\n    {        static void Main(string[] args)\n        {\n            // Create Spark session\n            SparkSession spark =\n                SparkSession\n                    .Builder()\n                    .AppName("TextSentimentExample")\n                    .GetOrCreate();\n\n            // Create DataFrame\n            DataFrame df = spark.CreateDataFrame(\n                new List<GenericRow>\n                {\n                    new GenericRow(new object[] {"I am so happy today, its sunny!", "en-US"}),\n                    new GenericRow(new object[] {"I am frustrated by this rush hour traffic", "en-US"}),\n                    new GenericRow(new object[] {"The cognitive services on spark aint bad", "en-US"})\n                },\n                new StructType(new List<StructField>\n                {\n                    new StructField("text", new StringType()),\n                    new StructField("language", new StringType())\n                })\n            );\n\n            // Create TextSentiment\n            var model = new TextSentiment()\n                .SetSubscriptionKey("YOUR_SUBSCRIPTION_KEY")\n                .SetLocation("eastus")\n                .SetTextCol("text")\n                .SetOutputCol("sentiment")\n                .SetErrorCol("error")\n                .SetLanguageCol("language");\n\n            // Transform\n            var outputDF = model.Transform(df);\n\n            // Display results\n            outputDF.Show();\n\n            // Stop Spark session\n            spark.Stop();\n        }\n    }\n}\n')),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/dotnet/api/microsoft.spark.sql.sparksession?view=spark-dotnet"},"SparkSession")," is the entrypoint\nof Apache Spark applications, which manages the context and information of your application. A DataFrame is a way of organizing\ndata into a set of named columns."),(0,r.kt)("p",null,"Create a ",(0,r.kt)("a",{parentName:"p",href:"https://mmlspark.blob.core.windows.net/docs/0.11.2/dotnet/classSynapse_1_1ML_1_1Cognitive_1_1TextSentiment.html"},"TextSentiment"),"\ninstance, set corresponding subscription key and other configurations. Then, apply transformation to the dataframe,\nwhich analyzes the sentiment based on each row, and stores result into output column."),(0,r.kt)("p",null,"The result of the transformation is stored in another DataFrame. At this point, no operations have taken place because\n.NET for Apache Spark lazily evaluates the data. The operation defined by the call to model.Transform doesn't execute until the Show method is called to display the contents of the transformed DataFrame to the console. Once you no longer need the Spark\nsession, use the Stop method to stop your session."),(0,r.kt)("h3",{id:"4-run-your-net-app"},"4. Run your .NET App"),(0,r.kt)("p",null,"Run the following command to build your application:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-powershell"},"dotnet build\n")),(0,r.kt)("p",null,"Navigate to your build output directory. For example, in Windows you could run ",(0,r.kt)("inlineCode",{parentName:"p"},"cd bin\\Debug\\net5.0"),".\nUse the spark-submit command to submit your application to run on Apache Spark."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-powershell"},"spark-submit --class org.apache.spark.deploy.dotnet.DotnetRunner --packages com.microsoft.azure:synapseml_2.12:0.11.2 --master local microsoft-spark-3-2_2.12-2.1.1.jar dotnet SynapseMLApp.dll\n")),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"--packages com.microsoft.azure:synapseml_2.12:0.11.2")," specifies the dependency on synapseml_2.12 version 0.11.2;\n",(0,r.kt)("inlineCode",{parentName:"p"},"microsoft-spark-3-2_2.12-2.1.1.jar")," specifies Microsoft.Spark version 2.1.1 and Spark version 3.2"),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"This command assumes you have downloaded Apache Spark and added it to your PATH environment variable so that you can use spark-submit.\nOtherwise, you'd have to use the full path (for example, C:\\bin\\apache-spark\\bin\\spark-submit or ~/spark/bin/spark-submit).")),(0,r.kt)("p",null,"When your app runs, the sentiment analysis result is written to the console."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"+-----------------------------------------+--------+-----+--------------------------------------------------+\n|                                     text|language|error|                                         sentiment|\n+-----------------------------------------+--------+-----+--------------------------------------------------+\n|          I am so happy today, its sunny!|   en-US| null|[{positive, null, {0.99, 0.0, 0.0}, [{I am so h...|\n|I am frustrated by this rush hour traffic|   en-US| null|[{negative, null, {0.0, 0.0, 0.99}, [{I am frus...|\n| The cognitive services on spark aint bad|   en-US| null|[{negative, null, {0.0, 0.01, 0.99}, [{The cogn...|\n+-----------------------------------------+--------+-----+--------------------------------------------------+\n")),(0,r.kt)("p",null,"Congratulations! You successfully authored and ran a .NET for SynapseML app.\nRefer to the ",(0,r.kt)("a",{parentName:"p",href:"https://mmlspark.blob.core.windows.net/docs/0.11.2/dotnet/index.html"},"developer docs")," for API guidance."),(0,r.kt)("h2",{id:"next"},"Next"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Refer to this ",(0,r.kt)("a",{parentName:"li",href:"https://docs.microsoft.com/en-us/dotnet/spark/tutorials/databricks-deployment"},"tutorial")," for deploying a .NET app to Databricks."),(0,r.kt)("li",{parentName:"ul"},"You could download compatible ",(0,r.kt)("a",{parentName:"li",href:"https://mmlspark.blob.core.windows.net/publicwasb/dotnet/install-worker.sh"},"install-worker.sh"),"\nand ",(0,r.kt)("a",{parentName:"li",href:"https://mmlspark.blob.core.windows.net/publicwasb/dotnet/db-init.sh"},"db-init.sh")," files needed for deployment on Databricks.")))}k.isMDXComponent=!0}}]);